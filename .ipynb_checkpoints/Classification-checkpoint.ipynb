{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Android Malware Classification\n",
    "This notebook explains how to run the Malware classification with a step by step process. You will learn how to import data, how to train your custom model, how to optimize it and how to test it on unlabelled data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Purpose\n",
    "We created this notebook to make our code as understadable and easy to use as possible.\n",
    "\n",
    "### Methodology\n",
    "The Classification is a two layer process. We first exploit Static Features of application to determine weither or not it is a malware and based on this static classification we analyse Dynamic features (network traffic and API calls) to refine the decision.\n",
    "In this notebbok we will : \n",
    "- import all the library and program that we need;\n",
    "- load the datasets;\n",
    "- Train a static classifier;\n",
    "- Test and evaluate the Static classification;\n",
    "- Train a dynamic classifier;\n",
    "- Test and evaluate the Dynamic classification;\n",
    "- Train a hybrid classifier\n",
    "- Test and evaluate the Hybrid classification;\n",
    "- Compare our results and conclude\n",
    "\n",
    "### WIP - improvements\n",
    "Use this section only if the notebook is not final.\n",
    "\n",
    "Notable TODOs:\n",
    "- todo 1;\n",
    "- todo 2;\n",
    "- todo 3.\n",
    "\n",
    "### Results\n",
    "Describe and comment the most important results.\n",
    "\n",
    "### Suggested next steps\n",
    "State suggested next steps, based on results obtained in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data import\n",
    "We retrieve all the required data for the Static analysis.\n",
    "It is made of two CSV files, one for testing and the other for training (training/testing : 60/40 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_firstlayer_data(path, data):\n",
    "    df = pd.read_csv(path+'StaticLayer_Intent_and_Permission_Bening&malware_'+data+'Smaples.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Istlayer_dataset_path = \"../Datasets/API-Intent-Traffic/Other_CSVs/1st_Layer/\"\n",
    "train_df = load_firstlayer_data(Istlayer_dataset_path, data = 'Training')\n",
    "test_df  = load_firstlayer_data(Istlayer_dataset_path, data = 'Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproccess_data(df):\n",
    "    d ={'Malware': True, 'Benign': False}\n",
    "    df['Binary_Type']=df['Binary_Type'].map(d)    \n",
    "    labels=df['Binary_Type']\n",
    "    df.drop(['Binary_Type','<family>','<category>', '<MD5>'], inplace=True, axis=1)\n",
    "    samples=df\n",
    "    return samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, train_labels = preproccess_data(train_df)\n",
    "test_samples , test_labels  = preproccess_data(test_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "#### Model Selection\n",
    "We decide to select for static analysis the random forest metho of the scikit-learn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_initial = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "We first train a model with automatic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_initial.fit(train_samples, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Predictions\n",
    "We now try to predict the test labels with or basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_predictions= rf_initial.predict(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9542586750788643\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, static_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Optimization\n",
    "We will now try to improve this result by finding better parameters\n",
    "\n",
    "#### Hyperparameter choice for improvement\n",
    "There is plempty of parameter that we can try to tweek in order to imporve our selection.\n",
    "But the more we take, the more step it will require in order to improve or result.\n",
    "We have to decide which hyperparameter we want to optimize, on which individual range we want to evaluate them and which metric we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "distrib = {\n",
    "    'max_depth'        : [*range(1,1000,10),None],\n",
    "    'min_samples_split' : [*range(5,len(train_samples)//2, 5)],\n",
    "    'n_estimators'     : [*range(1,500)],\n",
    "    'max_features'     : ['auto', 'sqrt', 'log2'],\n",
    "    'criterion'        : [\"gini\", \"entropy\"]\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try to find the individual best choice for each hyperparameter\n",
    "##### .... regardless of the others\n",
    "This naive method can be a first approach to fine-tune our model.\n",
    "It consists into determining the best choice for each hyperparameter one by one while the other are set at a constant value\n",
    "This is a simple and easy-to-understand way of optimising our model, but it can only spot local minima at best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RandomForrestOptimisation import global_optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_naive=global_optimisation(train_samples,\n",
    "                             train_labels,\n",
    "                             test_samples,\n",
    "                             test_labels,\n",
    "                             verbose=2,\n",
    "                             save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An advantage of the previous method is that we basically have the range of acceptance for each hyperparameters.\n",
    "Now we know that, for example, min_samples_split can take all the value beetween __ and __\n",
    "It's important because the ranges that we affect was nothing more than an initial guess and it could have led to undefined values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Estimation\n",
    "Now, lets try to find the global maxima of our metric f1. For this, a grid search (testing all the possible values for all the parameters) will be way too long.\n",
    "We will then try to estimate the set of best values by stochastic process.\n",
    "This step consist of a number N of random guess for a set of value and the memorizing of the set resulting in the best metric\n",
    "If N is a great number, we should correctly estimate the global best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RandomForrestOptimisation import Stochastic_Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomisedOptimisationParameters = Stochastic_Optimizer(train_samples,\n",
    "                                                        train_labels,\n",
    "                                                        test_samples,\n",
    "                                                        test_labels,\n",
    "                                                        distrib,\n",
    "                                                        n=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_stochastic = RandomForestClassifier(**RandomisedOptimisationParameters)\n",
    "rf_stochastic.fit(train_samples, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the HyperOpt library\n",
    "Now, We will try to use the HyperOpt library to find the best hyperparameters.\n",
    "This library is knowed for providing efficient and robust method for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RandomForrestOptimisation import HyperOpt_Resasarch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyperopt = HyperOpt_Resasarch(train_samples,\n",
    "                                 train_labels,\n",
    "                                 test_samples,\n",
    "                                 test_labels,\n",
    "                                 n_iter=1000,\n",
    "                                 save=False,\n",
    "                                 params_range=distrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then save our resulting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(rf_hyperopt, \"./RFNotebook.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "We will now evaluate our model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the confusion Matrix\n",
    "The confusion matrix allows us to know where our model is good at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Graphics import make_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cm_of_a_rf(model, test_samples, test_labels):\n",
    "    predictions = model.predict(test_samples)\n",
    "    cm, accuracy, precision, recall, f1 = get_metrics(test_labels, predictions)\n",
    "    categories=['Benign', 'Malware']\n",
    "    labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    make_confusion_matrix(cm, \n",
    "                      group_names=labels,\n",
    "                      categories=categories, \n",
    "                      cmap='binary',\n",
    "                      sklearn_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cm_of_a_rf(rf_hyperopt, test_samples, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the ROC-curve\n",
    "The ROC-curve is a good way of evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus : Difference beetween the 3 optimisation results\n",
    "We will now use the ROC curve of the 3 resulting model of the 3 different optimization method we used to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Classification\n",
    "We will now try to classify the application with network features.\n",
    "\n",
    "This classification is no longer binary but its multiclass.\n",
    "\n",
    "Indeed, we now try to class an application among 5 class, one is the benign class, and the other ones are different type of malware.\n",
    "\n",
    "We will report this multiclass classification into a inary classification later in the study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data selection\n",
    "We first need to see for which application we need dynamic features. We want to focus our study on the application for wich we have both network and static features\n",
    "\n",
    "For network data, we have for each application a .csv file containing the network flow emitted by a device during the running of the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There is : {} applications for wich we have static features'.format{len(train_labels)+len(test_labels)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are goin to list every application for wich we have dynamic features. For this we will have to list all the .csv file in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "Snd_layer_dataset='../Dataset/CICAndMal2017/'\n",
    "\n",
    "list_csv=glob.glob(Snd_layer_dataset+'/CSVS/**/*.csv', recursive=True)\n",
    "\n",
    "print('There is : {} applications for wich we have network features'.format{len(list_csv)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to select only applications for which we have both features. In order to do this we will use the hash of the application that is present in a column in the static dataset and as a name for the file in the dynamic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function can change a hash into the path of the dynamic .csv file of the corresponding application\n",
    "from common import change_hash_into_path\n",
    "\n",
    "#With this function we can get a partition of all the dynamic files, separated beetwen a testing and a training set\n",
    "def create_secondlayer_partition(Fstlayer_data_path, Sndlayer_data_path, Global_Testing_Ratio):\n",
    "    #We first want to load the static dataset\n",
    "    df_global=pd.read_csv(Fstlayer_data_path+'/StaticLayer_Intent_and_Permission_Bening&malware_TrainingSmaples.csv')\n",
    "    df_global.append(pd.read_csv(Fstlayer_data_path+'/StaticLayer_Intent_and_Permission_Bening&malware_TrainingSmaples.csv'))\n",
    "    \n",
    "    #We then want to get the hash of the application for wich we have static features\n",
    "    hashs=np.asarray(df_global['<MD5>'])#Récolte des hash d'applications restantes\n",
    "    \n",
    "    #We split the list of hash into a test set and a training set\n",
    "    hashs=train_test_split(hashs, test_size=Global_Testing_Ratio, shuffle=True)\n",
    "    \n",
    "    #We now change our hash into path to the corresponding .csv file for dynamic features\n",
    "    path=[change_hash_into_path(hashs[0], Sndlayer_data_path),change_hash_into_path(hashs[1], Sndlayer_data_path)]\n",
    "    \n",
    "    #We store the hash and there folowing path into a dictionnary\n",
    "    partition={'train':[path[0],hashs[0]],'test':[path[1],hashs[1]]}\n",
    "    return partition\n",
    "\n",
    "partition = create_secondlayer_partition(Istlayer_dataset_path,Snd_layer_data_path,3/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Import\n",
    "We can now try to import some dynamic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We will first try to import some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = partition['train'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will load the PCAP of an application and return a preprocess dataframe\n",
    "from common import load_secondlayer_data\n",
    "\n",
    "def get_all_data(paths):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for ID in paths:\n",
    "        x, y = load_secondlayer_data(ID)\n",
    "        X.append(x)\n",
    "        Y.append(np.asarray(y,dtype='float32'))\n",
    "    return X, Y\n",
    "\n",
    "X, Y = get_all_data(paths)\n",
    "\n",
    "print('Here it is an example of a preprocess pcap')\n",
    "print(X[3])\n",
    "print('and here it is its corresponding label')\n",
    "print(Y[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "We still need to process the samples by normalising them and change them to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To normalize our arry, we need to import the maximal an minimal value of each parameter of a pcap in the dataset.\n",
    "#We already have a file and a method to do so\n",
    "stat_values=pd.read_csv('Hybrid_Analysis/Dynamic_features_statistics.csv', index_col=0)\n",
    "stat_values=stat_values.to_dict()#We store them in a dictionnary\n",
    "\n",
    "#This method will normalise a given preprocessed pcap, based on the dictionnary stat_values\n",
    "from common import create_image_from_a_DataFrame\n",
    "\n",
    "#We redefine get_all_data in order to include the normalisation\n",
    "def get_all_data(paths, stat_values):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for ID in paths:\n",
    "        x, y = load_secondlayer_data(ID)\n",
    "        x = create_image_from_a_DataFrame(x,stat_values)\n",
    "        X.append(x)\n",
    "        Y.append(np.asarray(y,dtype='float32'))\n",
    "    return X, Y\n",
    "\n",
    "X, Y = get_all_data(paths)\n",
    "\n",
    "print('Here it is an example of a normalized pcap')\n",
    "print(X[3])\n",
    "print('and here it is its corresponding label')\n",
    "print(Y[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All The pcap doesn't have the same lenght, we will need either to add rows to the smaller ones or to remove rows from the bigger ones. We want all the samples in X to have the same shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add row to the smaller pcap : Padding\n",
    "We will add rows in all the pcap in order to match the lenght of the biggest.\n",
    "The row that we will add will be fill of a special value that we will later indicate to Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method will generate all the data of a gicen list of path with or without a padding\n",
    "from common import data_generation\n",
    "\n",
    "#We define the special value for the padding\n",
    "special_value=-1\n",
    "\n",
    "X, Y = data_generation(paths, padding = special_value)\n",
    "\n",
    "print('Here it is an example of a paded pcap')\n",
    "print(X[3])\n",
    "print('and here it is its corresponding label')\n",
    "print(Y[3])\n",
    "#The set of data has a define shape\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Remove row to the bigger pcap\n",
    "We will now remove row to all the pcap in order to match the lenght of the smallest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data_generation(paths, padding = None)\n",
    "\n",
    "print('Here it is an example of a non-paded pcap')\n",
    "print(X[3])\n",
    "print('and here it is its corresponding label')\n",
    "print(Y[3])\n",
    "#The set of data has a define shape\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method will generate all the data of a gicen list of path with or without a padding\n",
    "from common import data_generation\n",
    "\n",
    "#We define the special value for the padding\n",
    "special_value=-1\n",
    "\n",
    "X, Y = data_generation(paths, padding = special_value)\n",
    "\n",
    "print('Here it is an example of a paded pcap')\n",
    "print(X[3])\n",
    "print('and here it is its corresponding label')\n",
    "print(Y[3])\n",
    "#The set of data has a define shape\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The loading of the data is quite long, we will have to use a Data Generator.\n",
    "A Data Generator is an instance that will generate a batch of sample and label at each call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Data Generator\n",
    "\n",
    "A DataGenerator will generate a certain number of samples and labels at each iteration and will save us some memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):#Création d'un DataGenerator\n",
    "    \n",
    "    def __init__(self, list_IDs, batch_size=5, shuffle=True, padding=-1):#initialisation des parametre et definition des valeurs standart\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size=batch_size\n",
    "        self.padding=padding\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):#récupere un batch de donnée\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]#liste d'index du batch\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]#list de PCAP du batch\n",
    "        X, y = data_generation(list_IDs_temp, padding = self.padding)#récupération des observations et cibles du batch\n",
    "        y=y.reshape(self.batch_size,5)\n",
    "        return X.reshape(self.batch_size,*np.shape(X[0])), y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:#mélange des indexe\n",
    "            np.random.shuffle(self.indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traininggenerator=DataGenerator(partition['train'], 32, padding=None)\n",
    "testgenerator=DataGenerator(partition['test'], 32, padding=None)\n",
    "print(traininggenerator[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Imbalanced dataset\n",
    "\n",
    "Our dataset is highly imbalenced and have many more Benign application than malicious ones.\n",
    "We will affect a weight to each samples depending of its class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):#Création d'un DataGenerator\n",
    "    \n",
    "    def __init__(self, list_IDs, batch_size=5, shuffle=True, padding=-1, weight=False):#initialisation des parametre et definition des valeurs standart\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size=batch_size\n",
    "        self.padding=padding\n",
    "        self.weight=weight\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):#récupere un batch de donnée\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]#liste d'index du batch\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]#list de PCAP du batch\n",
    "        X, y = data_generation(list_IDs_temp, padding = self.padding)#récupération des observations et cibles du batch\n",
    "        y=y.reshape(self.batch_size,5)\n",
    "        if self.weight:\n",
    "            return X.reshape(self.batch_size,*np.shape(X[0])), y, self.get_weight(y)\n",
    "        else:\n",
    "            return X.reshape(self.batch_size,*np.shape(X[0])), y\n",
    "        \n",
    "        def get_weight(self, y):#Génération du poid pour une liste de cible\n",
    "        w0=0.67569546#Ces valeurs ont été déterminé experimentalement\n",
    "        w1=7.2109375\n",
    "        w2=7.2109375\n",
    "        w3=8.24107143\n",
    "        w4=8.24107143\n",
    "        weights=np.asarray([w0, w1, w2, w3, w4])\n",
    "        return np.dot(y, weights)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:#mélange des indexe\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traininggenerator=DataGenerator(partition['train'], 32, padding=special_value, weight=True)\n",
    "testgenerator=DataGenerator(partition['test'], 32, padding=special_value)\n",
    "\n",
    "print('Here it is an example of weight')\n",
    "print(traininggenerator[0][2][1])\n",
    "print('and here it is its corresponding label')\n",
    "print(traininggenerator[0][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training\n",
    "\n",
    "#### Model Selection\n",
    "We will use a multi-layer lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "model = Sequential()#On initialise le modèle dynamique\n",
    "model.add(Masking(mask_value=special_value, batch_input_shape = (None, None, 70)))#This laer will suppress the padded line\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(5, activation='softmax'))#Notre probleme est une classification en 5 familles d'applications\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x = traininggenerator, validation_data = testgenerator, epochs=300, verbose=1)#Entrainement du modèle hybride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Réalisation des courbes d'entrainements\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model Comparison\n",
    "\n",
    "We will now try to see the difference with a non padded and non weighted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traininggenerator=DataGenerator(partition['train'], 32, padding=None, weight=False)\n",
    "testgenerator=DataGenerator(partition['test'], 32, padding=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "model = Sequential()#On initialise le modèle dynamique\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(5, activation='softmax'))#Notre probleme est une classification en 5 familles d'applications\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model.fit(x = traininggenerator, validation_data = testgenerator, epochs=300, verbose=1)#Entrainement du modèle hybride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Réalisation des courbes d'entrainements\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Réalisation des courbes d'entrainements\n",
    "history1 = history.history['val_loss']\n",
    "history2 = history2.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(history1) + 1)\n",
    "\n",
    "plt.plot(epochs, history1, 'bo', label='Weighted_Padded')\n",
    "plt.plot(epochs, history2, 'r', label='No_weight_No_pad')\n",
    "plt.title('validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "In order to compare with the static method we need to predict the same type of data. In the dynamic method we've done a multiclass classification, whereas in the static method we've done a binary classification.\n",
    "Therefore, we need to convert the static prédiction into a binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method will convert a multi class prediction into a binary one\n",
    "from common import Binary_Classification\n",
    "\n",
    "testing_data, true_labels=data_generation(partition['test'])\n",
    "\n",
    "dynamic_prediction = model.predict(testing_data)\n",
    "\n",
    "dynamic_prediction = Binary_Classification(dynamic_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can now compare the static and the dynamic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import get_metrics\n",
    "from Graphics import make_confusion_matrix\n",
    "\n",
    "cm, accuracy, precision, recall, f1 = get_metrics(true_labels, dynamic_prediction)\n",
    "\n",
    "categories=['Benign', 'Malware']\n",
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "\n",
    "print(\"Dynamic Prediction\")\n",
    "make_confusion_matrix(cm, \n",
    "                      group_names=labels,\n",
    "                      categories=categories, \n",
    "                      cmap='binary',\n",
    "                      sklearn_matrix=True)\n",
    "\n",
    "print(\"Static Prediction\")\n",
    "cm, accuracy, precision, recall, f1 = get_metrics(true_labels, static_prediction)\n",
    "make_confusion_matrix(cm, \n",
    "                      group_names=labels,\n",
    "                      categories=categories, \n",
    "                      cmap='binary',\n",
    "                      sklearn_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The dynamic model is not good. It's even worse than the static one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hybrid Classification\n",
    "We will now try to classify the application with both network features and static features.\n",
    "\n",
    "We will just append the static prediction to the pcap analysed by the dynamic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data repartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For this we will first have to get the static predictions on all the application for which we have both static and dynamic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "In order to do so, we will have to decide which application will train which part of the model, such that an application d'ont train two different part of the model.\n",
    "We have decided that 40% of the application will be reserved to the training of the static model, 40% will be reserved for the training of the dynamic one and 20% will be reserved for the global test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These will be the application on wich we will train our static model\n",
    "train_samples, train_labels=load_firstlayer_data(Istlayer_dataset_path, data='Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Static Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_static = Sequential()\n",
    "\n",
    "model_static.add(Dense(units=8111, activation='relu')) # Il y a 8111 parametres statiques pour chaque applications\n",
    "model_static.add(Dense(units=256, activation='relu'))\n",
    "model_static.add(Dense(units=128, activation='relu'))\n",
    "model_static.add(Dense(units=64, activation='relu'))\n",
    "model_static.add(Dense(units=1, activation='sigmoid')) # On veut que le modele nous renvoie qu'une seule valeure\n",
    "\n",
    "model_static.compile(optimizer='adam',loss='binary_crossentropy',metrics='accuracy')\n",
    "model_static.fit(train_samples, train_labels, epochs=10) #On entraine le modèle sur 10 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make the static prédiction on all the other samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df=pd.read_csv(Istlayer_dataset_path+'StaticLayer_Intent_and_Permission_Bening&malware_'+'Training'+'Smaples.csv') #On charge les données statiques pour le reste des applications\n",
    "static_df=static_df.drop_duplicates(['<MD5>'])# On supprime les applications en doublons\n",
    "temp=static_df.drop(['Binary_Type','<family>','<category>', '<MD5>'], axis=1)# On supprimme les colonnes ininteressantes pour notre classification\n",
    "static_df['Static prediction']=model_static.predict(temp)# Pour chaque application, on réalise la prédiction avec le premier modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the dynamic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import create_secondlayer_partition\n",
    "partition, test = create_secondlayer_partition(Istlayer_dataset_path,Snd_layer_data_path,3/4,1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(partition['train'], static_df, max_values=dic, batch_size=32, padding=None)#On crée un générateur de donnée d'entrainement hybride\n",
    "validation_generator = DataGenerator(partition['validation'], static_df, max_values=dic, batch_size=64, padding=None)#On crée un générateur de donné de validation hybride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()#On initialise le modèle dynamique\n",
    "model.add(Masking(mask_value=special_value, batch_input_shape = (None, None, 71)))#On rajoute une couche de masque afin de supprimer les ligne de padding\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(5, activation='softmax'))#Notre probleme est une classification en 5 familles d'applications\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x = training_generator, validation_data = validation_generator, epochs=300, verbose=1)#Entrainement du modèle hybride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import get_test_data\n",
    "test_samples, test_labels = get_test_data(test, static_df, dic, Snd_layer_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_prediction=[u[0][70] for u in test_samples]#Extraction de la premiere prédiction statique\n",
    "\n",
    "static_prediction=np.round(np.asarray(static_prediction))#Transormation en label prédit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_prediction=model.predict(test_samples)#Prédiction hybride\n",
    "\n",
    "hybrid_prediction = Binary_Classification(hybrid_prediction)#Transormation de la prédiction multiclasse en prédiction binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = Binary_Classification(test_labels)#Transformation du label multiclasse en label binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_metrics(test_labels,static_prediction, get_cm=True))#Matrice de confusioon du premier modele statique\n",
    "print(get_metrics(test_labels,hybrid_prediction, get_cm=True))#Matrice de confusion du modèle hybride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "We report here relevant references:\n",
    "1. author1, article1, journal1, year1, url1\n",
    "2. author2, article2, journal2, year2, url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
