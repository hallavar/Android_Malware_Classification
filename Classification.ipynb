{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Android Malware Classification\n",
    "This notebook explains how to run the Malware classification with a step by step process. You will learn how to import data, how to train your custom model, how to optimize it and how to test it on unlabelled data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Purpose\n",
    "We created this notebook to make our code as understadable and easy to use as possible.\n",
    "\n",
    "### Methodology\n",
    "The Classification is a two layer process. We first exploit Static Features of application to determine weither or not it is a malware and based on this static classification we analyse Dynamic features (network traffic and API calls) to refine the decision.\n",
    "In this notebbok we will : \n",
    "- import all the library and program that we need;\n",
    "- load the datasets;\n",
    "- Train the static classifier;\n",
    "- Search for the optimal hyperparameters of the Static trained-classifier;\n",
    "- Test and evaluate the Static classification;\n",
    "-    (......)\n",
    "\n",
    "### WIP - improvements\n",
    "Use this section only if the notebook is not final.\n",
    "\n",
    "Notable TODOs:\n",
    "- todo 1;\n",
    "- todo 2;\n",
    "- todo 3.\n",
    "\n",
    "### Results\n",
    "Describe and comment the most important results.\n",
    "\n",
    "### Suggested next steps\n",
    "State suggested next steps, based on results obtained in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data import\n",
    "We retrieve all the required data for the Static analysis.\n",
    "It is made of two CSV files, one for testing and the other for training (training/testing : 60/40 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_firstlayer_data(path, data):\n",
    "    df = pd.read_csv(path+'StaticLayer_Intent_and_Permission_Bening&malware_'+data+'Smaples.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Istlayer_dataset_path = \"../Datasets/API-Intent-Traffic/Other_CSVs/1st_Layer/\"\n",
    "train_df = load_firstlayer_data(Istlayer_dataset_path, data = 'Training')\n",
    "test_df  = load_firstlayer_data(Istlayer_dataset_path, data = 'Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproccess_data(df):\n",
    "    d ={'Malware': True, 'Benign': False}\n",
    "    df['Binary_Type']=df['Binary_Type'].map(d)    \n",
    "    labels=df['Binary_Type']\n",
    "    df.drop(['Binary_Type','<family>','<category>', '<MD5>'], inplace=True, axis=1)\n",
    "    samples=df\n",
    "    return samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, train_labels = preproccess_data(train_df)\n",
    "test_samples , test_labels  = preproccess_data(test_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Model Selection\n",
    "We decide to select for static analysis the random forest metho of the scikit-learn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_initial = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "We first train a model with automatic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_initial.fit(train_samples, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Predictions\n",
    "We now try to predict the test labels with or basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= rf_initial.predict(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9542586750788643\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimization\n",
    "We will now try to improve this result by finding better parameters\n",
    "\n",
    "### Hyperparameter choice for improvement\n",
    "There is plempty of parameter that we can try to tweek in order to imporve our selection.\n",
    "But the more we take, the more step it will require in order to improve or result.\n",
    "We have to decide which hyperparameter we want to optimize, on which individual range we want to evaluate them and which metric we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "distrib = {\n",
    "    'max_depth'        : [*range(1,1000,10),None],\n",
    "    'min_samples_split' : [*range(5,len(train_samples)//2, 5)],\n",
    "    'n_estimators'     : [*range(1,500)],\n",
    "    'max_features'     : ['auto', 'sqrt', 'log2'],\n",
    "    'criterion'        : [\"gini\", \"entropy\"]\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to find the individual best choice for each hyperparameter\n",
    "#### .... regardless of the others\n",
    "This naive method can be a first approach to fine-tune our model.\n",
    "It consists into determining the best choice for each hyperparameter one by one while the other are set at a constant value\n",
    "This is a simple and easy-to-understand way of optimising our model, but it can only spot local minima at best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RandomForrestOptimisation import global_optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_naive=global_optimisation(train_samples,\n",
    "                             train_labels,\n",
    "                             test_samples,\n",
    "                             test_labels,\n",
    "                             verbose=2,\n",
    "                             save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An advantage of the previous method is that we basically have the range of acceptance for each hyperparameters.\n",
    "Now we know that, for example, min_samples_split can take all the value beetween __ and __\n",
    "It's important because the ranges that we affect was nothing more than an initial guess and it could have led to undefined values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Estimation\n",
    "Now, lets try to find the global maxima of our metric f1. For this, a grid search (testing all the possible values for all the parameters) will be way too long.\n",
    "We will then try to estimate the set of best values by stochastic process.\n",
    "This step consist of a number N of random guess for a set of value and the memorizing of the set resulting in the best metric\n",
    "If N is a great number, we should correctly estimate the global best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RandomForrestOptimisation import Stochastic_Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomisedOptimisationParameters = Stochastic_Optimizer(train_samples,\n",
    "                                                        train_labels,\n",
    "                                                        test_samples,\n",
    "                                                        test_labels,\n",
    "                                                        distrib,\n",
    "                                                        n=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_stochastic = RandomForestClassifier(**RandomisedOptimisationParameters)\n",
    "rf_stochastic.fit(train_samples, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the HyperOpt library\n",
    "Now, We will try to use the HyperOpt library to find the best hyperparameters.\n",
    "This library is knowed for providing efficient and robust method for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RandomForrestOptimisation import HyperOpt_Resasarch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyperopt = HyperOpt_Resasarch(train_samples,\n",
    "                                 train_labels,\n",
    "                                 test_samples,\n",
    "                                 test_labels,\n",
    "                                 n_iter=1000,\n",
    "                                 save=False,\n",
    "                                 params_range=distrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then save our resulting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(rf_hyperopt, \"./RFNotebook.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "We will now evaluate our model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the confusion Matrix\n",
    "The confusion matrix allows us to know where our model is good at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Graphics import make_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cm_of_a_rf(model, test_samples, test_labels):\n",
    "    predictions = model.predict(test_samples)\n",
    "    cm, accuracy, precision, recall, f1 = get_metrics(test_labels, predictions)\n",
    "    categories=['Benign', 'Malware']\n",
    "    labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    make_confusion_matrix(cm, \n",
    "                      group_names=labels,\n",
    "                      categories=categories, \n",
    "                      cmap='binary',\n",
    "                      sklearn_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cm_of_a_rf(rf_hyperopt, test_samples, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the ROC-curve\n",
    "The ROC-curve is a good way of evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus : Difference beetween the 3 optimisation results\n",
    "We will now use the ROC curve of the 3 resulting model of the 3 different optimization method we used to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "We report here relevant references:\n",
    "1. author1, article1, journal1, year1, url1\n",
    "2. author2, article2, journal2, year2, url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
